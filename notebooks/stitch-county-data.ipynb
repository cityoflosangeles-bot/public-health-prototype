{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US county-level data\n",
    "* Get everything in shape from NYT\n",
    "* Then add in JHU for recent observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coerce_fips_integer(df):\n",
    "    def integrify(x):\n",
    "        return int(float(x)) if not pd.isna(x) else None\n",
    "\n",
    "    cols = [\n",
    "        \"fips\",\n",
    "    ]\n",
    "    \n",
    "    new_cols = {c: df[c].apply(integrify, convert_dtype=False) for c in cols}\n",
    "    \n",
    "    return df.assign(**new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_county_fips(row):\n",
    "    if len(str(row.fips)) == 5:\n",
    "        return str(row.fips)\n",
    "    elif row.fips is not None:\n",
    "        return \"0\" + str(row.fips)\n",
    "    elif row.fips is None:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use NYT for county-level time-series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nyt_county_url = \"https://raw.githubusercontent.com/nytimes/covid-19-data/master/us-counties.csv\"\n",
    "county = pd.read_csv(nyt_county_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nyt_county(df):\n",
    "    keep_cols = ['date', 'county', 'state', 'fips', 'cases', 'deaths']\n",
    "    \n",
    "    df = df[keep_cols]\n",
    "    \n",
    "    # Coerce fips into integer, then convert to string\n",
    "    df = coerce_fips_integer(df)\n",
    "\n",
    "    df['fips'] = df.apply(correct_county_fips, axis = 1)\n",
    "\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "county = clean_nyt_county(county)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JHU data for 3/25 onward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu325 = gpd.read_file('../data/jhu_feature_layer_3_25_2020.geojson')\n",
    "jhu326 = gpd.read_file('../data/jhu_feature_layer_3_26_2020.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_327 = \"https://services1.arcgis.com/0MSEUqKaxRlEPj5g/ArcGIS/rest/services/ncov_cases_US/FeatureServer/0/query?where=1%3D1&objectIds=&time=&geometry=&geometryType=esriGeometryEnvelope&inSR=&spatialRel=esriSpatialRelIntersects&resultType=none&distance=0.0&units=esriSRUnit_Meter&returnGeodetic=false&outFields=OBJECTID%2C+Province_State%2C+Country_Region%2C+Last_Update%2C+Lat%2C+Long_%2C+Confirmed%2C+Recovered%2C+Deaths%2C+Active%2C+Admin2%2C+FIPS%2C+Combined_Key%2C+Incident_Rate%2C+People_Tested&returnGeometry=true&featureEncoding=esriDefault&multipatchOption=xyFootprint&maxAllowableOffset=&geometryPrecision=&outSR=&datumTransformation=&applyVCSProjection=false&returnIdsOnly=false&returnUniqueIdsOnly=false&returnCountOnly=false&returnExtentOnly=false&returnQueryGeometry=false&returnDistinctValues=false&cacheHint=false&orderByFields=&groupByFieldsForStatistics=&outStatistics=&having=&resultOffset=&resultRecordCount=&returnZ=false&returnM=false&returnExceededLimitFeatures=true&quantizationParameters=&sqlFormat=none&f=pgeojson&token=\"\n",
    "\n",
    "jhu327 = gpd.read_file(url_327)\n",
    "\n",
    "#jhu327.to_file(driver = 'GeoJSON', filename = '../data/jhu_feature_layer_3_27_2020.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu325['date'] = '3/25/2020'\n",
    "jhu326['date'] = '3/26/2020'\n",
    "jhu327['date'] = '3/27/2020'\n",
    "\n",
    "jhu1 = jhu325.append(jhu326).append(jhu327)\n",
    "jhu1['date'] = pd.to_datetime(jhu1.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the link\n",
    "nyt_geog = pd.read_csv('../data/nyt_us_county.csv')\n",
    "nyt_geog = nyt_geog[nyt_geog.fips.notna()][['fips', 'county', 'state']].drop_duplicates()\n",
    "\n",
    "nyt_geog = coerce_fips_integer(nyt_geog)\n",
    "nyt_geog['fips'] = nyt_geog.apply(correct_county_fips, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_jhu_county(df):\n",
    "    # Only keep certain columns and rename them to match NYT schema\n",
    "    keep_cols = ['Province_State', 'Country_Region', 'Lat', 'Long_',\n",
    "                 'Confirmed', 'Deaths', 'FIPS', \n",
    "                 'Incident_Rate', 'People_Tested', 'date']\n",
    "    \n",
    "    df = df[keep_cols]\n",
    "    \n",
    "    df.rename(columns = {'Confirmed': 'cases', 'Deaths': 'deaths', \n",
    "                         'FIPS': 'fips', 'Long_': 'Lon', \n",
    "                        'People_Tested': 'people_tested', 'Incident_Rate': 'incident_rate'}, inplace = True)\n",
    "        \n",
    "    # Use FIPS to merge in NYT columns for county and state names\n",
    "    # There are some values with no FIPS, which were all state observations. \n",
    "    # Drop them, use an inner join for merge.\n",
    "    df = pd.merge(df, nyt_geog, on = 'fips', how = 'inner', validate = 'm:1')\n",
    "    \n",
    "    \n",
    "    # Only keep certain columns and rename them to match NYT schema\n",
    "    drop_cols = ['Province_State', 'Country_Region']\n",
    "    \n",
    "    df = df.drop(columns = drop_cols)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "jhu1 = clean_jhu_county(jhu1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append old data -- do this once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_county_time_series = county.append(jhu1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing_stuff(df):\n",
    "    for col in ['Lat', 'Lon']:\n",
    "        df[col] = df.groupby(['fips', 'county', 'state'])[col].transform('max')\n",
    "    \n",
    "    # There's a FIPS that isn't caught because of a tilde for Dona Ana, New Mexico.\n",
    "    df['fips'] = df.apply(lambda row: \"35013\" if ('Ana' in row.county) & (row.fips is \"\")\n",
    "                          else row.fips, axis = 1)\n",
    "    \n",
    "    # Sort columns\n",
    "    col_order = ['county', 'state', 'fips', 'date', 'Lat', 'Lon', \n",
    "             'cases', 'deaths', 'incident_rate', 'people_tested']\n",
    "\n",
    "    df = df.reindex(columns = col_order).sort_values(['fips', 'date'])\n",
    "    \n",
    "    # Set data types for cases and deaths? Seems ok for now....\n",
    "    for col in ['incident_rate', 'people_tested']:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_county_time_series = fill_missing_stuff(us_county_time_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JHU data that needs to be a DAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Read in feature layer\n",
    "* Add date column\n",
    "* Apply clean_jhu_county function\n",
    "* Do upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we need to make sure our nyt_geog crosswalk is open\n",
    "nyt_geog = pd.read_csv('../data/nyt_us_county.csv')\n",
    "nyt_geog = nyt_geog[nyt_geog.fips.notna()][['fips', 'county', 'state']].drop_duplicates()\n",
    "\n",
    "nyt_geog = coerce_fips_integer(nyt_geog)\n",
    "nyt_geog['fips'] = nyt_geog.apply(correct_county_fips, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/frame.py:4025: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  return super(DataFrame, self).rename(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Pretend 3/27 is the current date showing for JHU\n",
    "jhu_today = clean_jhu_county(jhu327)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "jhu_today = fill_missing_stuff(jhu_today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now it's read to be upserted\n",
    "# Needs a drop_duplicates() line because we and JHU are updating multiple times a day\n",
    "# Also, keep Ian's localize then UTC timezone stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
