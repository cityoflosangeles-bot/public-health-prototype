{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# US state-level data\n",
    "* Get everything in shape from NYT\n",
    "* Then add in JHU for recent observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coerce_fips_integer(df):\n",
    "    def integrify(x):\n",
    "        return int(float(x)) if not pd.isna(x) else None\n",
    "\n",
    "    cols = [\n",
    "        \"fips\",\n",
    "    ]\n",
    "    \n",
    "    new_cols = {c: df[c].apply(integrify, convert_dtype=False) for c in cols}\n",
    "    \n",
    "    return df.assign(**new_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_state_fips(row):\n",
    "    if len(str(row.fips)) == 2:\n",
    "        return str(row.fips)\n",
    "    elif row.fips is not None:\n",
    "        return \"0\" + str(row.fips)\n",
    "    elif row.fips is None:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NYT state data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = pd.read_csv('../data/nyt_us_state.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nyt_state(df):\n",
    "    keep_cols = ['date', 'state', 'fips', 'cases', 'deaths']\n",
    "    \n",
    "    df = df[keep_cols]\n",
    "    \n",
    "    # Coerce fips into integer, then convert to string\n",
    "    df = coerce_fips_integer(df)\n",
    "\n",
    "    df['fips'] = df.apply(correct_state_fips, axis = 1)\n",
    "\n",
    "    df['date'] = pd.to_datetime(df.date)\n",
    "    \n",
    "    return df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = clean_nyt_state(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JHU state level data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_df = pd.read_csv('../data/us_county_time_series.csv')\n",
    "\n",
    "county_df['date'] = pd.to_datetime(county_df.date)\n",
    "recent = county_df[(county_df.date >= '3/26/2020') & (county_df.date <= '3/27/2020')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>county</th>\n",
       "      <th>state</th>\n",
       "      <th>fips</th>\n",
       "      <th>date</th>\n",
       "      <th>Lat</th>\n",
       "      <th>Lon</th>\n",
       "      <th>cases</th>\n",
       "      <th>deaths</th>\n",
       "      <th>incident_rate</th>\n",
       "      <th>people_tested</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>157</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>158</td>\n",
       "      <td>Autauga</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>32.539527</td>\n",
       "      <td>-86.644082</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>169</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>170</td>\n",
       "      <td>Baldwin</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>2020-03-27</td>\n",
       "      <td>30.727750</td>\n",
       "      <td>-87.722071</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>310</td>\n",
       "      <td>Blount</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>2020-03-26</td>\n",
       "      <td>33.982109</td>\n",
       "      <td>-86.567906</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0   county    state    fips       date        Lat        Lon  \\\n",
       "158         157  Autauga  Alabama  1001.0 2020-03-26  32.539527 -86.644082   \n",
       "159         158  Autauga  Alabama  1001.0 2020-03-27  32.539527 -86.644082   \n",
       "173         169  Baldwin  Alabama  1003.0 2020-03-26  30.727750 -87.722071   \n",
       "174         170  Baldwin  Alabama  1003.0 2020-03-27  30.727750 -87.722071   \n",
       "177         310   Blount  Alabama  1009.0 2020-03-26  33.982109 -86.567906   \n",
       "\n",
       "     cases  deaths  incident_rate  people_tested  \n",
       "158      5       0            NaN            NaN  \n",
       "159      6       0            NaN            NaN  \n",
       "173      4       0            NaN            NaN  \n",
       "174      5       0            NaN            NaN  \n",
       "177      2       0            NaN            NaN  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create state totals\n",
    "jhu_state_totals = recent.groupby(['state', 'Lat', 'Lon', 'date']).agg({'cases':'sum', \n",
    "                                                                        'deaths':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = state.append(jhu_state_totals, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "coordinates = jhu_state_totals[['state', 'Lat', 'Lon']].drop_duplicates()\n",
    "\n",
    "def fill_missing_stuff(df):\n",
    "    df = pd.merge(df.drop(columns = ['Lat', 'Lon']), coordinates, on = 'state', how = 'left')\n",
    "    \n",
    "    # Sort columns\n",
    "    col_order = ['state', 'fips', 'date', 'Lat', 'Lon', \n",
    "             'cases', 'deaths', 'incident_rate', 'people_tested']\n",
    "\n",
    "    df = df.reindex(columns = col_order).sort_values(['fips', 'date'])\n",
    "    \n",
    "    # Set data types for cases and deaths? Seems ok for now....\n",
    "    for col in ['incident_rate', 'people_tested']:\n",
    "        df[col] = df[col].astype(float)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fill_missing_stuff(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "fix_me = df[df.Lat.isna()]\n",
    "rest_of_df = df[df.Lat.notna()]\n",
    "\n",
    "fix_latitude = {\n",
    "    'Virgin Islands': 18.3358,\n",
    "    'Puerto Rico': 18.2,\n",
    "    'Guam': 13.4443\n",
    "}\n",
    "\n",
    "fix_longitude = {\n",
    "    'Virgin Islands': -64.8963,\n",
    "    'Puerto Rico': -66.5,\n",
    "    'Guam': 144.7937     \n",
    "}\n",
    "\n",
    "\n",
    "fix_me['Lat'] = fix_me.state.map(fix_latitude)\n",
    "fix_me['Lon'] = fix_me.state.map(fix_longitude)\n",
    "\n",
    "full_df = rest_of_df.append(fix_me, sort = False)\n",
    "\n",
    "full_df = full_df.sort_values(['fips', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Grab from JHU\\nUS Virgin Islands,  18.3358, -64.8963\\nPR, 18.2, -66.5\\nGuam, 13.4443, 144.7937\\nname, lat, long\\n'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Grab from JHU\n",
    "US Virgin Islands,  18.3358, -64.8963\n",
    "PR, 18.2, -66.5\n",
    "Guam, 13.4443, 144.7937\n",
    "name, lat, long\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_csv('../data/us_state_time_series.csv')\n",
    "full_df.to_parquet('../data/us_state_time_series.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
